{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326dde48-dcb5-4d50-886f-a9aea53f7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=0\n"
     ]
    }
   ],
   "source": [
    "# allows showing the tensorboard widget\n",
    "%load_ext tensorboard\n",
    "\n",
    "# allow import reloading\n",
    "%load_ext autoreload\n",
    "\n",
    "# set to 1 for cuda debugging\n",
    "%set_env CUDA_LAUNCH_BLOCKING=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b4b18f-5a44-4c60-80a1-af4ea6ec6573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f783f117f8b4d1e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f783f117f8b4d1e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the tensorboard widget\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b59ac42-274b-44e6-9742-63c28e934982",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import pytorch_lightning as lightning\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pathlib\n",
    "from data import MeshDataset, SingleTensorDataset\n",
    "from models import PointCloudsModule\n",
    "\n",
    "import utils\n",
    "import blender_plot as bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09cee7ff-6e3e-4562-a6a5-3fef982c17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", dpi=250, titlesize=6)\n",
    "plt.rc(\"legend\", fontsize=6)\n",
    "\n",
    "plots_path = pathlib.Path(\"plots\")\n",
    "samples_path = pathlib.Path(\"samples\")\n",
    "\n",
    "plots_path.mkdir(parents=True, exist_ok=True)\n",
    "samples_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73197324-f13a-40fc-b0f4-d73f6bd21793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7efd517c66b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ba126b-92a5-4962-bdbb-6d6016170dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4dea8f3-7b80-4681-8263-7e4a70935341",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_mesh = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459cc8be-d5b0-4625-b84f-cca78b4586fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3192, 799, 908)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = MeshDataset(root=data_root / \"processed\", split=\"train\", shapes=\"all\", samples=samples_per_mesh)\n",
    "n_train = int(0.8 * len(train_data))\n",
    "n_val = len(train_data) - n_train\n",
    "\n",
    "seed = torch.seed()\n",
    "torch.manual_seed(42)\n",
    "train_data, val_data = random_split(train_data, [n_train, n_val])\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "test_data = MeshDataset(root=data_root / \"processed\", split=\"test\", shapes=\"all\", samples=samples_per_mesh)\n",
    "\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15379993-3c90-4dc8-b76c-f05e71e0f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 3\n",
    "conditions = 128\n",
    "\n",
    "encoder_hparams = dict(\n",
    "    inputs=inputs,\n",
    "    points=samples_per_mesh,\n",
    "    conditions=conditions,\n",
    "    kind=\"deterministic\",\n",
    "    dropout=0.1,\n",
    "    widths=[[], []], # reimplement, maybe\n",
    "    activation=\"selu\",\n",
    "    checkpoints=True,\n",
    "    Lambda=0.5,\n",
    ")\n",
    "\n",
    "rectifier_hparams = dict(\n",
    "    inputs=inputs,\n",
    "    conditions=conditions,\n",
    "    dropout=0.1,\n",
    "    widths=[256, 512, 512, 512, 256],\n",
    "    activation=\"selu\",\n",
    "    checkpoints=True,\n",
    "    integrator=\"euler\",\n",
    ")\n",
    "\n",
    "hparams = dict(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=5,\n",
    "    optimizer=\"adam\",\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    batch_size=80,\n",
    "    accumulate_batches=None,\n",
    "    gradient_clip=1.0,\n",
    "    encoder_hparams=encoder_hparams,\n",
    "    rectifier_hparams=rectifier_hparams,\n",
    "    augment_noise=0.05,\n",
    "    mmd_scales=torch.logspace(-2, 2, 20),\n",
    "    mmd_samples=None,\n",
    "    time_samples=2,\n",
    "    encoder_weight=1.0,\n",
    "    rectifier_weight=1.0,\n",
    "    profiler=\"simple\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1777bdf3-3328-4af9-82e6-c3047d625dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloudsModule(\n",
      "  (encoder): Encoder(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=128, bias=True)\n",
      "      (1): SELU()\n",
      "      (2): GlobalMultimaxPool1d()\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (5): SELU()\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (8): SELU()\n",
      "      (9): GlobalMultimaxPool1d()\n",
      "      (10): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (11): SELU()\n",
      "      (12): Dropout(p=0.1, inplace=False)\n",
      "      (13): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (14): SELU()\n",
      "      (15): GlobalMultimaxPool1d()\n",
      "      (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (17): SELU()\n",
      "      (18): Dropout(p=0.1, inplace=False)\n",
      "      (19): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (20): SELU()\n",
      "      (21): GlobalMultimaxPool1d()\n",
      "      (22): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (23): SELU()\n",
      "      (24): Dropout(p=0.1, inplace=False)\n",
      "      (25): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (26): SELU()\n",
      "      (27): GlobalAvgPool1d()\n",
      "      (28): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (29): SELU()\n",
      "      (30): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (rectifier): Rectifier(\n",
      "    (network): Sequential(\n",
      "      (Input Layer): Linear(in_features=132, out_features=256, bias=True)\n",
      "      (Input Activation): SELU()\n",
      "      (Dropout 1): Dropout1d(p=0.1, inplace=False)\n",
      "      (Hidden Layer 1): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (Hidden Activation 1): SELU()\n",
      "      (Dropout 2): Dropout1d(p=0.1, inplace=False)\n",
      "      (Hidden Layer 2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Hidden Activation 2): SELU()\n",
      "      (Dropout 3): Dropout1d(p=0.1, inplace=False)\n",
      "      (Hidden Layer 3): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Hidden Activation 3): SELU()\n",
      "      (Dropout 4): Dropout1d(p=0.1, inplace=False)\n",
      "      (Hidden Layer 4): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (Hidden Activation 4): SELU()\n",
      "      (Output Layer): Linear(in_features=256, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = PointCloudsModule(train_data, val_data, test_data, **hparams)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429874c-e671-4b7c-944d-8f488f7cdae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | Encoder   | 1.5 M \n",
      "1 | rectifier | Rectifier | 823 K \n",
      "----------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "9.338     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/code/python/point-clouds/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1558: PossibleUserWarning: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f5b3c3144b4e1aa54694a2aaee0da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = model.configure_trainer()\n",
    "\n",
    "with torch.autograd.enable_grad():\n",
    "    model.train()\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2dde3-5550-41d0-870c-4a61fca998c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = model.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "# model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3af216-45e6-4508-91a8-2c40fbfe5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = trainer.checkpoint_callback.best_model_path\n",
    "checkpoint = \"lightning_logs/version_5/checkpoints/last.ckpt\"\n",
    "model = model.load_from_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78b0e6-09f7-46ce-b00e-b784e5a895d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc513c6-3a2d-4e59-bcb9-8860606a1b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bfa2a4-1d25-4e1c-8303-03c995efd03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(samples):\n",
    "    cols = int(np.sqrt(samples.shape[0]))\n",
    "    rows = int(np.ceil(samples.shape[0] / cols))\n",
    "\n",
    "    fig = plt.figure(figsize=(cols, rows))\n",
    "\n",
    "    for i, points in enumerate(samples):\n",
    "        ax = fig.add_subplot(rows, cols, i + 1, projection=\"3d\")\n",
    "        ax.scatter(points[:, 0], points[:, 1], points[:, 2], s=1, color=\"black\", alpha=0.5, lw=0)\n",
    "        ax.set_axis_off()\n",
    "    \n",
    "    # set the spacing between subplots\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.0, hspace=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4b5b3-bf47-488c-bdc3-a7a386c8a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.sample(n_shapes=9, n_points=2048, steps=100)\n",
    "torch.save(samples, samples_path / \"random_samples.pt\")\n",
    "\n",
    "plot_samples(samples)\n",
    "plt.gcf().suptitle(\"Random Samples\")\n",
    "plt.savefig(plots_path / \"random_samples.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce06ab1-265a-496c-aea4-c9c026cbd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.sample(n_shapes=1024, n_points=2048, steps=100)\n",
    "torch.save(samples, samples_path / \"many_random_samples.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e8760-6419-470f-ac71-8de16ca8cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "sample = model.sample(n_shapes=1, n_points=4096, steps=100).squeeze()\n",
    "torch.save(sample, samples_path / \"sample.pt\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "ax.scatter(sample[:, 0], sample[:, 1], sample[:, 2], s=1, color=\"black\", alpha=0.5, lw=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fdb4dc-32f3-4dcd-9b41-9c7dc312b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a high-fidelity render of the above\n",
    "s = bp.DefaultScene()\n",
    "s.scatter(sample, alpha=0.5)\n",
    "img = s.render(plots_path / \"renders\" / \"sample.png\", resolution=(1200, 1200), samples=128)\n",
    "s.save(samples_path / \"blendfiles\" / \"sample.blend\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984e3af-8ef8-44eb-87ad-d0f206d327ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample conditions with constant noise\n",
    "samples = model.sample_shapes(n_shapes=9, n_points=2048, steps=100)\n",
    "torch.save(samples, samples_path / \"shapes.pt\")\n",
    "\n",
    "plot_samples(samples)\n",
    "plt.gcf().suptitle(\"Sampling From Constant Noise With Varying Condition\")\n",
    "plt.savefig(plots_path / \"shapes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a9ab3-8d01-4170-9fc2-3a3734cd299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample noise with constant condition\n",
    "samples = model.sample_variations(n_shapes=9, n_points=2048, steps=100)\n",
    "torch.save(samples, samples_path / \"variations.pt\")\n",
    "\n",
    "plot_samples(samples)\n",
    "plt.gcf().suptitle(\"Sampling from Constant Condition with Varying Noise\")\n",
    "plt.savefig(plots_path / \"variations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf8f53-2daa-4d03-9054-52e257a6f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 8\n",
    "cols = 6\n",
    "points = 2048\n",
    "steps = 100\n",
    "\n",
    "conditions = model.encoder.distribution.sample((cols,)).to(model.device)\n",
    "noise = model.rectifier.distribution.sample((rows, points)).to(model.device)\n",
    "\n",
    "conditions = utils.repeat_dim(conditions, rows, dim=0)\n",
    "noise = noise.repeat_interleave(cols, dim=0)\n",
    "\n",
    "points, _time = model.rectifier.inverse(noise, condition=conditions, steps=steps)\n",
    "\n",
    "plot_samples(points)\n",
    "fig = plt.gcf()\n",
    "fig.suptitle(\"Sampling with Varying Noise or Condition\")\n",
    "fig.supxlabel(\"Condition\")\n",
    "fig.supylabel(\"Noise\")\n",
    "plt.savefig(plots_path / \"shape_variations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3727fc7-b2f0-45aa-80d4-c9ba160d2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct random train samples\n",
    "random_indices = torch.randperm(len(train_data))[:9]\n",
    "random_samples = torch.stack([train_data[i] for i in random_indices])\n",
    "\n",
    "reconstructions = model.reconstruct(random_samples, steps=100)\n",
    "torch.save(reconstructions, samples_path / \"reconstructions.pt\")\n",
    "\n",
    "plot_samples(reconstructions)\n",
    "plt.gcf().suptitle(\"Reconstructions\")\n",
    "plt.savefig(plots_path / \"reconstructions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f56372-4b3e-4341-9cfe-3b60ef827864",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(random_samples)\n",
    "plt.gcf().suptitle(\"Train Data\")\n",
    "plt.savefig(plots_path / \"train.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ff623-cb52-459a-99d8-1f40000520c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
